<h1 align="center">
  Hi, I'm <a href="https://kolakivy.github.io/" target="_blank">Qiwei Liang (æ¢æ£‹ç‚œ) ğŸ‘‹</a> <br>
	<img alt="GitHub User's stars" src="https://img.shields.io/github/stars/kolakivy">
	<img alt="GitHub followers" src="https://img.shields.io/github/followers/kolakivy">
<br>
<a href="https://kolakivy.github.io/" target="_blank" style="margin-top: 100px"><img src="assets/school.png" height="70px" style="margin-bottom:-1px"></a>
</h1>

---

## ğŸŒŸ About Me
Hello! Iâ€™m Qiwei Liang (æ¢æ£‹ç‚œ), a undergraduate student majoring in Robotics Engineering at Shenzhen University, expected to graduate in July 2026. Currently, I am conducting research at the Humanoid Computing Lab, HKUST(gz), under the supervision of [Renjing Xu](https://scholar.google.com/citations?user=Mu__bJEAAAAJ&hl=en). 

Before diving into research, I was an IoT enthusiast dedicated to developing IoT products with the goal of improving peopleâ€™s lives. I was also the **national champion of the China Collegiate IoT Design Competition** (ç‰©è”ç½‘ç«èµ›å…¨å›½æ€»å† å†›).

My research interests lie in Embodied AI, particularly in Robotic Manipulation (VLA, VA, RL), Robot Learning, and Whole-Body Control. Fundamentally, my work revolves around Exploring the Pinnacle of Wisdom.

---

## ğŸš€ Publications
**First / Co-first Author25**
- <span style="color: #5409e1;">(ESWA ä¸€åŒºTop)</span> **STAR: Empowering Semi-Supervised Medical Image Segmentation with SAM-based Teacher-Student Architecture and Contrastive Consistency Regularization**, [paper](https://www.sciencedirect.com/science/article/abs/pii/S0957417425022699)
- <span style="color: #5409e1ff;">(UR)</span> **Video2Reward++: Advancing Robot Skill Acquisition via Video-guided Reward Generation**
- <span style="color: #5409e1ff;">(ECAI 2024)</span> **Video2Reward: Generating Reward Function from Videos for Legged Robot Behavior Learning**, [[paper]](https://arxiv.org/abs/2412.05515), [[webpage]](https://djjiery.github.io/Video2Reward.github.io/)
- <span style="color: #5409e1ff;">(CINT 2024)</span> **iKnowiSee: AR Glasses with Language Learning Translation System and Identity Recognition System Built Based on Large Pre-trained Models of Language and Vision and Internet of Things Technology**, [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-3948-6_2)
- <span style="color: #5409e1ff;">(arxiv 2025)</span> **Whole-Body Coordination for Dynamic Object Grasping with Legged Manipulators**, [[webpage]](https://kolakivy.github.io/DQ/)


**Co-Author**
- <span style="color: #5409e1ff;">(arxiv 2025)</span> **RoboTwin 2.0: Autonomous Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation**, [[paper]](https://arxiv.org/abs/2506.18088), [[webpage]](https://robotwin-platform.github.io/)
- <span style="color: #5409e1ff;">(arxiv 2025)</span> **FASR-Net: Unsupervised Shadow Removal Leveraging Inherent Frequency Priors**, [[paper]](https://arxiv.org/abs/2504.05779)
- <span style="color: #5409e1ff;">(ICLR WS 2025)</span> **Text2World: Benchmarking Large Language Models for Symbolic World Model Generation**, [[paper]](https://openreview.net/pdf?id=dIQNOxuBay), [[webpage]](https://text-to-world.github.io/)

---

## ğŸ›  Skills & Tools
<p align="center">
  <img src="https://skillicons.dev/icons?i=python,pytorch,cpp,ros,arduino,raspberrypi,matlab,git,linux" />
</p>

---

## ğŸ“Š Dynamic GitHub Widgets
<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=KolaKivy&show_icons=true&theme=radical" alt="stats" />
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=KolaKivy&theme=radical" alt="streak" />
</p>

---

## ğŸ“« Contact
- âœ‰ï¸ kola337599@gmail.com  
- ğŸŒ Personal site: https://kolakivy.github.io/  
- ğŸ“š Google Scholar / Github / Xiaohongshu links are on my website. 

---